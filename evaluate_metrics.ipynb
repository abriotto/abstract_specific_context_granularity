{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:07:29.291893Z",
     "start_time": "2024-07-16T08:07:29.267959Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from utils.analysis_from_interaction import *\n",
    "from egg.core.language_analysis import Disent\n",
    "from language_analysis_local import TopographicSimilarityConceptLevel, encode_target_concepts_for_topsim\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate metrics from stored interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:08:08.711033Z",
     "start_time": "2024-07-16T08:08:08.695755Z"
    }
   },
   "outputs": [],
   "source": [
    "datasets = ('(3,4)', '(3,8)', '(3,16)', '(4,4)', '(4,8)', '(5,4)')\n",
    "n_attributes = (3, 3, 3, 4, 4, 5)\n",
    "n_values = (4, 8, 16, 4, 8, 4)\n",
    "paths = ['results/' + d + '_game_size_10_vsf_3/' for d in datasets]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "datasets = ['(3,16)', '(5,4)']\n",
    "n_attributes = [3, 5]\n",
    "n_values = [16, 4]\n",
    "paths = ['results/' + d + '_game_size_10_vsf_0/' for d in datasets]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T08:09:28.275646Z",
     "start_time": "2024-07-16T08:09:28.245488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasets = ['(3,4)',]\n",
    "n_attributes = [3,]\n",
    "n_values = [16,]\n",
    "paths = ['results/' + d + '_game_size_10_vsf_0/' for d in datasets]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:09:29.671294Z",
     "start_time": "2024-07-16T08:09:29.654134Z"
    }
   },
   "outputs": [],
   "source": [
    "context_unaware = True # whether original or context_unaware simulations are evaluated\n",
    "length_cost = True # whether length_cost was applied\n",
    "no_cost = False # set to True to consider baselines without a cost\n",
    "early_stopping = True\n",
    "if length_cost:\n",
    "    if context_unaware and not no_cost:\n",
    "        setting = 'length_cost/context_unaware'\n",
    "    elif context_unaware and no_cost:\n",
    "        setting = 'length_cost/no_cost_context_unaware'\n",
    "    elif not context_unaware and not no_cost:\n",
    "        setting = 'length_cost/context_aware'\n",
    "    else:\n",
    "        setting = 'length_cost/no_cost_context_aware'\n",
    "else:\n",
    "    if context_unaware:\n",
    "        setting = 'context_unaware'\n",
    "    else:\n",
    "        setting = 'standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# get n_epochs if early stopping\n",
    "if early_stopping:\n",
    "    \n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        \n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(5):\n",
    "    \n",
    "            path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "            with open(os.path.join(path_to_run, 'loss_and_metrics.pkl'), 'rb') as input_file:\n",
    "                data = pickle.load(input_file)\n",
    "                final_epoch = max(data['loss_train'].keys())\n",
    "                n_epochs.append(final_epoch)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "        \n",
    "else:\n",
    "    n_epochs_all_data = []\n",
    "    for d in range(len(datasets)):\n",
    "        n_epochs = []\n",
    "        \n",
    "        for run in range(5):\n",
    "            n_epochs.append(300)\n",
    "                \n",
    "        n_epochs_all_data.append(n_epochs)\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T08:09:30.401265Z",
     "start_time": "2024-07-16T08:09:30.375965Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy scores: MI, effectiveness, efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:09:47.813120Z",
     "start_time": "2024-07-16T08:09:31.947690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,16)_game_size_10_vsf_0/length_cost/context_unaware/0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:315: RuntimeWarning: invalid value encountered in divide\n",
      "  (m_entropy_concept_x_context + c_entropy_concept_x_context - joint_entropy_concept_x_context)\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:324: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_effectiveness_conc_x_cont = ((joint_entropy_concept_x_context - m_entropy_concept_x_context)\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:331: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_consistency_conc_x_cont = (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/(3,16)_game_size_10_vsf_0/length_cost/context_unaware/1/\n",
      "results/(3,16)_game_size_10_vsf_0/length_cost/context_unaware/2/\n",
      "results/(3,16)_game_size_10_vsf_0/length_cost/context_unaware/3/\n",
      "results/(3,16)_game_size_10_vsf_0/length_cost/context_unaware/4/\n",
      "results/(5,4)_game_size_10_vsf_0/length_cost/context_unaware/0/\n",
      "results/(5,4)_game_size_10_vsf_0/length_cost/context_unaware/1/\n",
      "results/(5,4)_game_size_10_vsf_0/length_cost/context_unaware/2/\n",
      "results/(5,4)_game_size_10_vsf_0/length_cost/context_unaware/3/\n",
      "results/(5,4)_game_size_10_vsf_0/length_cost/context_unaware/4/\n"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/' \n",
    "        print(path_to_run)\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = information_scores(interaction, attributes, values, normalizer=\"arithmetic\")\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'entropy_scores.pkl', 'wb'))\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  message length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:09:54.912352Z",
     "start_time": "2024-07-16T08:09:47.814579Z"
    }
   },
   "outputs": [],
   "source": [
    "# we evaluated message length per hierarchy level after training but \n",
    "# you can also use the HierarchicalMessageLength callback and store the results \n",
    "# TODO: Message length results look weird, needs to be fixed!\n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "            \n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = message_length_per_hierarchy_level(interaction, attributes)\n",
    "        \n",
    "        pickle.dump(scores, open(path_to_run + 'message_length_hierarchical.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  symbol redundancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T08:10:05.508611Z",
     "start_time": "2024-07-16T08:09:54.914949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n",
      "/Users/kkobrock/Projects/phdproject1/emergent-abstractions/utils/analysis_from_interaction.py:444: RuntimeWarning: invalid value encountered in divide\n",
      "  return symbol_frequency / att_val_frequency, mutual_information\n"
     ]
    }
   ],
   "source": [
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    attributes = n_attributes[d]\n",
    "    values = n_values[d]\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    vocab_size = 5\n",
    "    \n",
    "    for run in range(5): \n",
    "        \n",
    "        \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "        redundancy, MI = symbol_frequency(interaction, attributes, values, vocab_size)\n",
    "        \n",
    "        scores = {'symbol_redundancy': redundancy, 'MI_symbol-attribute_value': MI}\n",
    "        \n",
    "        pickle.dump(scores, open(path_to_run + 'symbol_redundancy.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  compositionality scores: topsim, posdis, bosdis"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### topsim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-16T08:10:05.504843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,16) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.08798733041272157, 'topsim_specific_train': 0.0922713906792324, 'topsim_generic_train': 0.19371895425328975, 'topsim_val': 0.0924831570958416, 'topsim_specific_val': 0.09618475745719318, 'topsim_generic_val': 0.20187673771323275}\n",
      "dataset (3,16) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.11215146570282497, 'topsim_specific_train': 0.13436131601114285, 'topsim_generic_train': 0.2773403319009128, 'topsim_val': 0.11951324170626798, 'topsim_specific_val': 0.1505813558712337, 'topsim_generic_val': 0.15993739442827656}\n",
      "dataset (3,16) run 2\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.07334648843272874, 'topsim_specific_train': 0.09263116379143263, 'topsim_generic_train': 0.32097572662709495, 'topsim_val': 0.09050957507860175, 'topsim_specific_val': 0.11172942430089493, 'topsim_generic_val': 0.23220436423800367}\n",
      "dataset (3,16) run 3\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.10116215908232955, 'topsim_specific_train': 0.11158384178918529, 'topsim_generic_train': 0.25084315756432246, 'topsim_val': 0.10788186061335793, 'topsim_specific_val': 0.11268381259010579, 'topsim_generic_val': 0.2188737213298373}\n",
      "dataset (3,16) run 4\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.1165596858278171, 'topsim_specific_train': 0.11869154511358823, 'topsim_generic_train': 0.18414603111799407, 'topsim_val': 0.1310280228782987, 'topsim_specific_val': 0.13622113119336982, 'topsim_generic_val': 0.18306238890608006}\n",
      "dataset (5,4) run 0\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.20388248870099876, 'topsim_specific_train': 0.2523350394305923, 'topsim_generic_train': 0.22485161928312952, 'topsim_val': 0.22792552079438894, 'topsim_specific_val': 0.27953727412418833, 'topsim_generic_val': 0.2149518168331215}\n",
      "dataset (5,4) run 1\n",
      "... topsim computed\n",
      "... topsim computed\n",
      "{'topsim_train': 0.25889356929346147, 'topsim_specific_train': 0.3145210763852099, 'topsim_generic_train': 0.24160471871124095, 'topsim_val': 0.2684800280552723, 'topsim_specific_val': 0.33869002273670906, 'topsim_generic_val': 0.21019854648297284}\n",
      "dataset (5,4) run 2\n"
     ]
    }
   ],
   "source": [
    "# topsim\n",
    "# although topsim values are stored throughout training if callbacks are verbose, we reevaluate the\n",
    "# final topsim scores with more data points \n",
    "\n",
    "samples = 5000 # maybe shuffle from these because otherwise I just take the first 5,000 (which might not be the best)\n",
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    dim = [n_values[d]]*n_attributes[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        topsim_final = {}\n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "                \n",
    "                  \n",
    "            messages = interaction.message.argmax(dim=-1)\n",
    "            sender_input = interaction.sender_input\n",
    "            n_targets = int(sender_input.shape[1]/2)\n",
    "            # get target objects and fixed vectors to re-construct concepts\n",
    "            target_objects = sender_input[:, :n_targets]\n",
    "            target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "            # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "            (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "            # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "            objects = objects + 1\n",
    "            concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "            specific_idx = np.where(np.sum(fixed, axis=1)==n_attributes[d])[0]\n",
    "            messages_specific = messages[specific_idx]\n",
    "            concepts_specific = concepts[specific_idx]\n",
    "            \n",
    "            generic_idx = np.where(np.sum(fixed, axis=1)==1)[0]\n",
    "            messages_generic = messages[generic_idx]\n",
    "            concepts_generic = concepts[generic_idx]\n",
    "\n",
    "            messages = [msg.tolist() for msg in messages]\n",
    "            messages_specific = [msg.tolist() for msg in messages_specific]\n",
    "            messages_generic = [msg.tolist() for msg in messages_generic]\n",
    "\n",
    "            encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "            # randomly take samples when more than 5000 samples are available\n",
    "            # if len(encoded_input) > samples: \n",
    "            #     print(\"sampling\")\n",
    "            #     sample_indices = random.sample(range(len(encoded_input)), samples)\n",
    "            #     sampled_input = [encoded_input[i] for i in sample_indices]\n",
    "            #     sampled_messages = [messages[i] for i in sample_indices]\n",
    "            #     print(\"start computing\")\n",
    "            #     print(len(sampled_input), len(sampled_input[0]), len(sampled_input[0][0]))\n",
    "            #     topsim = TOPSIM.compute_topsim(sampled_input, sampled_messages)\n",
    "            # else:\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[0:samples], messages[0:samples]) # default: hausdorff distance for concepts, edit distance for messages\n",
    "            # if len(concepts_specific) > samples:\n",
    "            #     print(\"sampling specific\")\n",
    "            #     sample_indices_specific = random.sample(range(len(concepts_specific)), samples)\n",
    "            #     sampled_input_specific = [concepts_specific[i] for i in sample_indices_specific]\n",
    "            #     sampled_messages_specific = [messages_specific[i] for i in sample_indices_specific]\n",
    "            #     topsim_specific = TOPSIM.compute_topsim(sampled_input_specific, sampled_messages_specific, \n",
    "            #                                             meaning_distance_fn=\"edit\")\n",
    "            # else:\n",
    "            topsim_specific = TOPSIM.compute_topsim(concepts_specific[0:samples], messages_specific[0:samples], \n",
    "                                                        meaning_distance_fn=\"edit\")\n",
    "            \n",
    "            topsim_generic = TOPSIM.compute_topsim(concepts_generic[0:samples], messages_generic[0:samples],\n",
    "                                                   meaning_distance_fn=\"edit\")\n",
    "\n",
    "            print('... topsim computed')\n",
    "\n",
    "            topsim_final['topsim_' + mode] = topsim\n",
    "            topsim_final['topsim_specific_' + mode] = topsim_specific\n",
    "            topsim_final['topsim_generic_' + mode] = topsim_generic\n",
    "    \n",
    "        pickle.dump(topsim_final, open(path_to_run +  \"topsim_final.pkl\", \"wb\" ) )\n",
    "        print(topsim_final)        "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Topsim over time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset (3,4) run 0\n",
      "dataset (3,4) run 1\n",
      "dataset (3,4) run 2\n",
      "dataset (3,4) run 3\n",
      "dataset (3,4) run 4\n",
      "dataset (3,8) run 0\n",
      "dataset (3,8) run 1\n",
      "dataset (3,8) run 2\n",
      "dataset (3,8) run 3\n",
      "dataset (3,8) run 4\n",
      "dataset (3,16) run 0\n",
      "dataset (3,16) run 1\n"
     ]
    }
   ],
   "source": [
    "for d, dataset in enumerate(datasets):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    for run in range(5):\n",
    "        print(\"dataset\", dataset, \"run\", run)\n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        path_to_interaction_val = (path_to_run + 'interactions/validation/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        \n",
    "        for mode in ['train', 'val']:\n",
    "\n",
    "            if mode == 'train':\n",
    "                interaction = torch.load(path_to_interaction_train)\n",
    "            elif mode == 'val':\n",
    "                interaction = torch.load(path_to_interaction_val)\n",
    "\n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        messages = [msg.tolist() for msg in messages]\n",
    "        encoded_input = encode_target_concepts_for_topsim(sender_input)\n",
    "        dim = [n_values[0]] * n_attributes[0]\n",
    "        TOPSIM = TopographicSimilarityConceptLevel(dim, is_gumbel=True)\n",
    "        \n",
    "        samples = 5000\n",
    "        num_batches = len(messages) // samples + (len(messages) % samples > 0)\n",
    "        topsim_over_time = []\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            messages_batch = messages[i * samples:(i + 1) * samples]\n",
    "            topsim = TOPSIM.compute_topsim(encoded_input[i * samples:(i + 1) * samples], messages_batch)\n",
    "            topsim_over_time.append(topsim)\n",
    "            \n",
    "        pickle.dump(topsim_over_time, open(path_to_run +  \"topsim_over_time.pkl\", \"wb\" ) )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-14T14:07:47.776462Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Posdis and Bosdis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# use Disent callback from egg\n",
    "\n",
    "for d in range(len(datasets)): \n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "    \n",
    "    path = paths[d]\n",
    "    dim = [n_values[d]] * n_attributes[d]\n",
    "    n_features = n_attributes[d] * n_values[d]\n",
    "    vs_factor = int(path[-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    print(\"data set\", dim)\n",
    "    \n",
    "    for run in range(5):\n",
    "        \n",
    "        posdis_bosdis = {}\n",
    "    \n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction_train = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction_train)\n",
    "        \n",
    "        messages = interaction.message.argmax(dim=-1)\n",
    "        sender_input = interaction.sender_input\n",
    "        n_targets = int(sender_input.shape[1]/2)\n",
    "        # get target objects and fixed vectors to re-construct concepts\n",
    "        target_objects = sender_input[:, :n_targets]\n",
    "        target_objects = k_hot_to_attributes(target_objects, n_values[d])\n",
    "        # concepts are defined by a list of target objects (here one sampled target object) and a fixed vector\n",
    "        (objects, fixed) = retrieve_concepts_sampling(target_objects)\n",
    "        # add one such that zero becomes an empty attribute for the calculation (_)\n",
    "        objects = objects + 1\n",
    "        concepts = torch.from_numpy(objects * (np.array(fixed)))\n",
    "\n",
    "        # concrete/specific concepts: where all attributes are fixed\n",
    "        concepts_specific = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]])\n",
    "        messages_specific = messages[torch.sum(torch.from_numpy(fixed), dim=1) == n_attributes[d]]\n",
    "\n",
    "        # generic concepts: where only one attribute is fixed\n",
    "        concepts_generic = torch.tensor(\n",
    "            objects[torch.sum(torch.from_numpy(fixed), dim=1) == 1])\n",
    "        messages_generic = messages[torch.sum(torch.from_numpy(fixed), dim=1) == 1]\n",
    "        \n",
    "        posdis_specific = Disent.posdis(concepts_specific, messages_specific)\n",
    "        bosdis_specific = Disent.bosdis(concepts_specific, messages_specific, vocab_size)\n",
    "\n",
    "        posdis_generic = Disent.posdis(concepts_generic, messages_generic)\n",
    "        bosdis_generic = Disent.bosdis(concepts_generic, messages_generic, vocab_size)\n",
    "        \n",
    "        posdis = Disent.posdis(torch.from_numpy(objects), messages)\n",
    "        bosdis = Disent.bosdis(torch.from_numpy(objects), messages, vocab_size)\n",
    "        \n",
    "        posdis_bosdis['posdis_specific'] = posdis_specific\n",
    "        posdis_bosdis['bosdis_specific'] = bosdis_specific\n",
    "        posdis_bosdis['posdis_generic'] = posdis_generic\n",
    "        posdis_bosdis['bosdis_generic'] = bosdis_generic\n",
    "        posdis_bosdis['posdis'] = posdis\n",
    "        posdis_bosdis['bosdis'] = bosdis\n",
    "\n",
    "        print(posdis_bosdis)\n",
    "    \n",
    "        pickle.dump(posdis_bosdis, open(path_to_run + \"posdis_bosdis.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Posdis and bosdis concept x context"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# bosdis concept x context\n",
    "from utils.analysis_from_interaction import bosdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "    \n",
    "    for run in range(5):\n",
    "\n",
    "        path_to_run = paths[d] + '/' + str(setting) +'/' + str(run) + '/' \n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = bosdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'bosdis_scores.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# posdis concept x context\n",
    "from utils.analysis_from_interaction import posdis\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    n_epochs = n_epochs_all_data[d]\n",
    "\n",
    "    vs_factor = int(paths[d][-2])\n",
    "    vocab_size = (n_values[d] + 1) * vs_factor + 1\n",
    "\n",
    "    for run in range(5):\n",
    "        path_to_run = paths[d] + '/' + str(setting) + '/' + str(run) + '/'\n",
    "        print(path_to_run)\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        #print(path_to_interaction)\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        scores = posdis(interaction, attributes, values, vocab_size)\n",
    "\n",
    "        pickle.dump(scores, open(path_to_run + 'posdis_scores.pkl', 'wb'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## co-occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not yet implemented:\n",
    "\n",
    "for d in range(len(datasets)):\n",
    "    \n",
    "    vs_factor = int(paths[d][-2])\n",
    "    \n",
    "    for run in range(5): \n",
    "        \n",
    "        path_to_run = paths[d] + str(setting) +'/' + str(run) + '/'\n",
    "        path_to_interaction = (path_to_run + 'interactions/train/epoch_' + str(n_epochs[run]) + '/interaction_gpu0')\n",
    "        interaction = torch.load(path_to_interaction)\n",
    "\n",
    "        attributes = n_attributes[d]\n",
    "        values = n_values[d]\n",
    "        \n",
    "        scores = cooccurrence_per_hierarchy_level(interaction, attributes, values, vs_factor)\n",
    "\n",
    "        print(scores)\n",
    "        \n",
    "        pickle.dump(scores, open(path_to_run + 'normalized_cooccurrence.pkl', 'wb'))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

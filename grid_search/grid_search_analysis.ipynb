{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from grid_search_utils import get_grid_search_results\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    attributes  values  game_size  vocab_size_factor  n_epochs  batch_size  \\\n",
      "0          3.0     4.0       10.0                3.0      60.0        32.0   \n",
      "1          3.0     4.0       10.0                3.0      60.0        32.0   \n",
      "2          3.0     4.0       10.0                3.0      60.0        64.0   \n",
      "3          3.0     4.0       10.0                3.0      60.0        64.0   \n",
      "4          3.0     4.0       10.0                3.0      60.0        64.0   \n",
      "..         ...     ...        ...                ...       ...         ...   \n",
      "91         5.0    16.0       10.0                3.0      60.0       128.0   \n",
      "92         5.0    16.0       10.0                3.0      60.0       128.0   \n",
      "93         5.0    16.0       10.0                3.0      60.0       128.0   \n",
      "94         5.0    16.0       10.0                3.0      60.0       128.0   \n",
      "95         5.0    16.0       10.0                3.0      60.0       128.0   \n",
      "\n",
      "    learning_rate  hidden_size  temp_update  temperature  train_loss  \\\n",
      "0          0.0005        128.0         0.97          1.5    0.124104   \n",
      "1          0.0005        128.0         0.99          1.5    0.075740   \n",
      "2          0.0005        256.0         0.97          1.5    0.059822   \n",
      "3          0.0005        256.0         0.99          1.5    0.027655   \n",
      "4          0.0010        128.0         0.97          1.5    0.055749   \n",
      "..            ...          ...          ...          ...         ...   \n",
      "91         0.0005        256.0         0.99          1.5    0.092553   \n",
      "92         0.0010        128.0         0.97          1.5    0.159513   \n",
      "93         0.0010        128.0         0.99          1.5    0.075594   \n",
      "94         0.0010        256.0         0.97          1.5    0.140712   \n",
      "95         0.0010        256.0         0.99          1.5    0.123718   \n",
      "\n",
      "    train_accuracy  test_loss  test_accuracy  \n",
      "0         0.956726   0.142591       0.947987  \n",
      "1         0.972803   0.119088       0.953584  \n",
      "2         0.979610   0.109251       0.970671  \n",
      "3         0.991560   0.088316       0.979899  \n",
      "4         0.979332   0.087449       0.969231  \n",
      "..             ...        ...            ...  \n",
      "91        0.969170   0.123182       0.960304  \n",
      "92        0.945700   0.269291       0.920439  \n",
      "93        0.974038   0.137039       0.962681  \n",
      "94        0.946665   0.195692       0.929861  \n",
      "95        0.954403   0.197325       0.924653  \n",
      "\n",
      "[96 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# give directory name\n",
    "directory = \"new_07-02\"\n",
    "get_grid_search_results(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"results_\" + directory + \".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New grid search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes [3 5]\n",
      "values [ 4 16]\n",
      "game_size [10]\n",
      "vocab_size_factor [3.]\n",
      "n_epochs [60.]\n",
      "batch_size [ 32  64 128]\n",
      "learning_rate [0.0005 0.001 ]\n",
      "hidden_size [128 256]\n",
      "temp_update [0.97 0.99]\n",
      "temperature [1.5]\n"
     ]
    }
   ],
   "source": [
    "# parameters that were tested\n",
    "for col in data.columns[:-4]:\n",
    "    print(col, data[col].unique())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 3 4\n",
      "attributes             3.000000\n",
      "values                 4.000000\n",
      "game_size             10.000000\n",
      "vocab_size_factor      3.000000\n",
      "n_epochs              60.000000\n",
      "batch_size            64.000000\n",
      "learning_rate          0.001000\n",
      "hidden_size          256.000000\n",
      "temp_update            0.990000\n",
      "temperature            1.500000\n",
      "train_loss             0.012773\n",
      "train_accuracy         0.996425\n",
      "test_loss              0.072355\n",
      "test_accuracy          0.988811\n",
      "Name: 15, dtype: float64\n",
      "dataset: 3 16\n",
      "attributes             3.000000\n",
      "values                16.000000\n",
      "game_size             10.000000\n",
      "vocab_size_factor      3.000000\n",
      "n_epochs              60.000000\n",
      "batch_size            32.000000\n",
      "learning_rate          0.001000\n",
      "hidden_size          128.000000\n",
      "temp_update            0.970000\n",
      "temperature            1.500000\n",
      "train_loss             0.028504\n",
      "train_accuracy         0.993097\n",
      "test_loss              0.054402\n",
      "test_accuracy          0.985243\n",
      "Name: 28, dtype: float64\n",
      "dataset: 5 4\n",
      "attributes             5.000000\n",
      "values                 4.000000\n",
      "game_size             10.000000\n",
      "vocab_size_factor      3.000000\n",
      "n_epochs              60.000000\n",
      "batch_size            64.000000\n",
      "learning_rate          0.000500\n",
      "hidden_size          256.000000\n",
      "temp_update            0.990000\n",
      "temperature            1.500000\n",
      "train_loss             0.024013\n",
      "train_accuracy         0.991678\n",
      "test_loss              0.023753\n",
      "test_accuracy          0.994840\n",
      "Name: 59, dtype: float64\n",
      "dataset: 5 16\n",
      "attributes             5.000000\n",
      "values                16.000000\n",
      "game_size             10.000000\n",
      "vocab_size_factor      3.000000\n",
      "n_epochs              60.000000\n",
      "batch_size            32.000000\n",
      "learning_rate          0.001000\n",
      "hidden_size          256.000000\n",
      "temp_update            0.990000\n",
      "temperature            1.500000\n",
      "train_loss             0.030772\n",
      "train_accuracy         0.993210\n",
      "test_loss              0.071362\n",
      "test_accuracy          0.986145\n",
      "Name: 79, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "attributes = [3, 5]\n",
    "values = [4, 16]\n",
    "datasets = list(itertools.product(attributes, values))\n",
    "index = data.index\n",
    "for (attributes, values) in datasets:\n",
    "    print(\"dataset:\", attributes, values)\n",
    "    per_dataset = data[(data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "    max_test_acc = per_dataset['test_accuracy'].idxmax()\n",
    "    print(per_dataset.loc[index[max_test_acc]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size\n",
    "Highest mean test accuracies with batch size 32. Batch size 64 sometimes yields higher single test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 4 batch size 32 maximum 0.9866970777511596 mean 0.965672068297863\n",
      "Dataset 3 4 batch size 64 maximum 0.9888112545013428 mean 0.9120209068059921\n",
      "Dataset 3 4 batch size 128 maximum 0.9743242859840392 mean 0.8610631749033928\n",
      "Dataset 3 16 batch size 32 maximum 0.9852430820465088 mean 0.9501819163560867\n",
      "Dataset 3 16 batch size 64 maximum 0.9756014347076416 mean 0.9515627771615982\n",
      "Dataset 3 16 batch size 128 maximum 0.9500000476837158 mean 0.9119450151920319\n",
      "Dataset 5 4 batch size 32 maximum 0.988092839717865 mean 0.9565313011407852\n",
      "Dataset 5 4 batch size 64 maximum 0.9948399066925048 mean 0.8953777551651001\n",
      "Dataset 5 4 batch size 128 maximum 0.9719080924987792 mean 0.9307041242718697\n",
      "Dataset 5 16 batch size 32 maximum 0.98614501953125 mean 0.9659816101193428\n",
      "Dataset 5 16 batch size 64 maximum 0.975000023841858 mean 0.940387487411499\n",
      "Dataset 5 16 batch size 128 maximum 0.9626811742782592 mean 0.9302194714546204\n"
     ]
    }
   ],
   "source": [
    "batch_size = [32, 64, 128]\n",
    "for (attributes, values) in datasets:\n",
    "    for bs in batch_size:\n",
    "        per_dataset = data[(data[\"batch_size\"] == bs) & (data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "        max_bs = per_dataset['test_accuracy'].idxmax()\n",
    "        max_test_acc = per_dataset.loc[index[max_bs]][\"test_accuracy\"]\n",
    "        mean_test_acc = per_dataset['test_accuracy'].mean()\n",
    "        print(\"Dataset\", attributes, values, \"batch size\", bs, \"maximum\", max_test_acc, \"mean\", mean_test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate\n",
    "No big differences between 0.001 and 0.0005, thus I chose 0.001 for shorter training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 4 learning rate 0.001 maximum 0.9888112545013428 mean 0.8803680539131165\n",
      "Dataset 3 4 learning rate 0.0005 maximum 0.9798986911773682 mean 0.9454693794250488\n",
      "Dataset 3 16 learning rate 0.001 maximum 0.9852430820465088 mean 0.9454561372598013\n",
      "Dataset 3 16 learning rate 0.0005 maximum 0.9587628841400146 mean 0.93033700188001\n",
      "Dataset 5 4 learning rate 0.001 maximum 0.9719080924987792 mean 0.9219005852937698\n",
      "Dataset 5 4 learning rate 0.0005 maximum 0.9948399066925048 mean 0.9331748684247335\n",
      "Dataset 5 16 learning rate 0.001 maximum 0.98614501953125 mean 0.948737715681394\n",
      "Dataset 5 16 learning rate 0.0005 maximum 0.9827377796173096 mean 0.9423213303089142\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.0005]\n",
    "for (attributes, values) in datasets:\n",
    "    for lr in learning_rate:\n",
    "        per_dataset = data[(data[\"learning_rate\"] == lr) & (data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "        max_lr = per_dataset['test_accuracy'].idxmax()\n",
    "        max_test_acc = per_dataset.loc[index[max_lr]][\"test_accuracy\"]\n",
    "        mean_test_acc = per_dataset['test_accuracy'].mean()\n",
    "        print(\"Dataset\", attributes, values, \"learning rate\", lr, \"maximum\", max_test_acc, \"mean\", mean_test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden size\n",
    "Highest mean test accuracies with hidden size 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 4 hidden size 128 maximum 0.9757732152938844 mean 0.9418245404958725\n",
      "Dataset 3 4 hidden size 256 maximum 0.9888112545013428 mean 0.8840128928422928\n",
      "Dataset 3 16 hidden size 128 maximum 0.9852430820465088 mean 0.9435793707768122\n",
      "Dataset 3 16 hidden size 256 maximum 0.9756014347076416 mean 0.932213768362999\n",
      "Dataset 5 4 hidden size 128 maximum 0.9687063694000244 mean 0.9431305974721909\n",
      "Dataset 5 4 hidden size 256 maximum 0.9948399066925048 mean 0.9119448562463125\n",
      "Dataset 5 16 hidden size 128 maximum 0.9765203595161438 mean 0.9371389995018641\n",
      "Dataset 5 16 hidden size 256 maximum 0.98614501953125 mean 0.953920046488444\n"
     ]
    }
   ],
   "source": [
    "hidden_size = [128, 256]\n",
    "for (attributes, values) in datasets:\n",
    "    for hs in hidden_size:\n",
    "        per_dataset = data[(data[\"hidden_size\"] == hs) & (data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "        max_hs = per_dataset['test_accuracy'].idxmax()\n",
    "        max_test_acc = per_dataset.loc[index[max_hs]][\"test_accuracy\"]\n",
    "        mean_test_acc = per_dataset['test_accuracy'].mean()\n",
    "        print(\"Dataset\", attributes, values, \"hidden size\", hs, \"maximum\", max_test_acc, \"mean\", mean_test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature update\n",
    "Only slight differences, but 0.99 seems to be a bit better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 3 4 temperature update 0.97 maximum 0.9757732152938844 mean 0.8844468494256338\n",
      "Dataset 3 4 temperature update 0.99 maximum 0.9888112545013428 mean 0.9413905839125315\n",
      "Dataset 3 16 temperature update 0.97 maximum 0.9852430820465088 mean 0.9415563096602758\n",
      "Dataset 3 16 temperature update 0.99 maximum 0.9756014347076416 mean 0.9342368294795355\n",
      "Dataset 5 4 temperature update 0.97 maximum 0.9687063694000244 mean 0.9349933664004008\n",
      "Dataset 5 4 temperature update 0.99 maximum 0.9948399066925048 mean 0.9200820873181025\n",
      "Dataset 5 16 temperature update 0.97 maximum 0.9644876718521118 mean 0.9374628613392512\n",
      "Dataset 5 16 temperature update 0.99 maximum 0.98614501953125 mean 0.9535961846510569\n"
     ]
    }
   ],
   "source": [
    "temperature_update = [0.97, 0.99]\n",
    "for (attributes, values) in datasets:\n",
    "    for ts in temperature_update:\n",
    "        per_dataset = data[(data[\"temp_update\"] == ts) & (data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "        max_ts = per_dataset['test_accuracy'].idxmax()\n",
    "        max_test_acc = per_dataset.loc[index[max_ts]][\"test_accuracy\"]\n",
    "        mean_test_acc = per_dataset['test_accuracy'].mean()\n",
    "        print(\"Dataset\", attributes, values, \"temperature update\", ts, \"maximum\", max_test_acc, \"mean\", mean_test_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attributes [3 4]\n",
      "values [3 4]\n",
      "game_size [ 3  4 10]\n",
      "vocab_size_factor [3.]\n",
      "n_epochs [100.]\n",
      "batch_size [32 64]\n",
      "learning_rate [0.0005 0.001 ]\n",
      "hidden_size [128 256]\n",
      "temp_update [0.97 0.99]\n",
      "temperature [1.  1.5 2. ]\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns[:-4]:\n",
    "    print(col, data[col].unique())        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "     attributes  values  game_size  vocab_size_factor  n_epochs  batch_size  \\\n",
      "104           3       3         10                3.0     100.0          32   \n",
      "\n",
      "     learning_rate  hidden_size  temp_update  temperature  train_loss  \\\n",
      "104         0.0005          256         0.99          1.5    0.002427   \n",
      "\n",
      "     train_accuracy  test_loss  test_accuracy  \n",
      "104        0.999246   0.045159       0.992708  \n",
      "(3, 4)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "positional indexers are out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/indexing.py:1587\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3895\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3896\u001b[0m \u001b[39mInternal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3897\u001b[0m \u001b[39mattribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3900\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3901\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3902\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3903\u001b[0m \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/generic.py:3886\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m-> 3886\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3887\u001b[0m     indices,\n\u001b[1;32m   3888\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   3889\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3890\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[1;32m   3891\u001b[0m )\n\u001b[1;32m   3892\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/internals/managers.py:965\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39mif\u001b[39;00m convert_indices:\n\u001b[0;32m--> 965\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39;49mverify)\n\u001b[1;32m    967\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/indexers/utils.py:286\u001b[0m, in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m--> 286\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mindices are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m indices\n",
      "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/kkobrock/Projects/phdproject1/emergent-abstractions/grid_search/grid_search_analysis.ipynb Cell 6\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kkobrock/Projects/phdproject1/emergent-abstractions/grid_search/grid_search_analysis.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m per_dataset \u001b[39m=\u001b[39m data[(data[\u001b[39m\"\u001b[39m\u001b[39mattributes\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m attributes) \u001b[39m&\u001b[39m (data[\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m values)]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/kkobrock/Projects/phdproject1/emergent-abstractions/grid_search/grid_search_analysis.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m max_test_acc \u001b[39m=\u001b[39m per_dataset[\u001b[39m'\u001b[39m\u001b[39mtest_accuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39midxmax()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kkobrock/Projects/phdproject1/emergent-abstractions/grid_search/grid_search_analysis.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(per_dataset\u001b[39m.\u001b[39;49miloc[[max_test_acc]])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/indexing.py:1616\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1614\u001b[0m \u001b[39m# a list of integers\u001b[39;00m\n\u001b[1;32m   1615\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m-> 1616\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_list_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1618\u001b[0m \u001b[39m# a single integer\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1620\u001b[0m     key \u001b[39m=\u001b[39m item_from_zerodim(key)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/egg/lib/python3.9/site-packages/pandas/core/indexing.py:1590\u001b[0m, in \u001b[0;36m_iLocIndexer._get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1587\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   1588\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# re-raise with different error message\u001b[39;00m\n\u001b[0;32m-> 1590\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mpositional indexers are out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
     ]
    }
   ],
   "source": [
    "attributes = [3, 4]\n",
    "values = [3, 4]\n",
    "for dataset in itertools.product(attributes, values):\n",
    "    print(dataset)\n",
    "    attributes, values = dataset\n",
    "    per_dataset = data[(data[\"attributes\"] == attributes) & (data[\"values\"] == values)]\n",
    "    max_test_acc = per_dataset['test_accuracy'].idxmax()\n",
    "    print(per_dataset.iloc[[max_test_acc]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset (3,3): 3 3 3 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for game size 3: nan\n",
      "Mean accuracy for game size 4: nan\n",
      "Mean accuracy for game size 10: 0.9538681525737047\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[data['game_size'] == 3, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 3:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['game_size'] == 4, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 4:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['game_size'] == 10, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 10:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset (3,4): 4 4 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Game size\n",
    "Larger game sizes are better: 10 or 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for game size 3: 0.9142084374819717\n",
      "Mean accuracy for game size 10: 0.9616841533117824\n",
      "Mean accuracy for game size 20: 0.968630887567997\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[data['game_size'] == 3, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 3:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['game_size'] == 10, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 10:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['game_size'] == 20, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for game size 20:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch size\n",
    "Batch size does not really seem to matter, but smaller is a bit better: 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for batch size 32: 0.9498066183638899\n",
      "Mean accuracy for batch size 64: 0.9485835441284709\n",
      "Mean accuracy for batch size 128: 0.9456388966904746\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[data['batch_size'] == 32, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 32:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['batch_size'] == 64, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 64:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[data['batch_size'] == 128, 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 128:\", mean_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for batch size 32 and game size 10 or 20: 0.9689533325533072\n",
      "Mean accuracy for batch size 64: 0.9656351047257582\n",
      "Mean accuracy for batch size 128: 0.9608841240406036\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[(data['batch_size'] == 32) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 32 and game size 10 or 20:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['batch_size'] == 64) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 64:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['batch_size'] == 128) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for batch size 128:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate\n",
    "Does not matter a lot but smaller is better: 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for learning rate 0.0005 and game size 10 or 20: 0.9677117218573889\n",
      "Mean accuracy for learning rate 0.001: 0.9626033190223906\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[(data['learning_rate'] == 0.0005) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for learning rate 0.0005 and game size 10 or 20:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['learning_rate'] == 0.001) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for learning rate 0.001:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden size\n",
    "Does not really matter but smaller is better: 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for hidden size 128 and game size 10 or 20: 0.9658779733710818\n",
      "Mean accuracy for hidden size 256: 0.9644370675086975\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[(data['hidden_size'] == 128) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for hidden size 128 and game size 10 or 20:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['hidden_size'] == 256) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for hidden size 256:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature\n",
    "Higher is better: 1.5 or 2 rather than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for temperature 1 and game size 10 or 20: 0.9398398324847221\n",
      "Mean accuracy for temperature 1.5: 0.9743879847228527\n",
      "Mean accuracy for temperature 2: 0.9812447441120943\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[(data['temperature'] == 1.0) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for temperature 1 and game size 10 or 20:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['temperature'] == 1.5) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for temperature 1.5:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['temperature'] == 2.0) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for temperature 2:\", mean_train_acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temperature update\n",
    "Closer to 1 is better: 0.99 rather than 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for temperature update 0.97 and game size 10 or 20: 0.9560216731495328\n",
      "Mean accuracy for temperature update 0.99: 0.9742933677302467\n"
     ]
    }
   ],
   "source": [
    "mean_train_acc = data.loc[(data['temp_update'] == 0.97) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for temperature update 0.97 and game size 10 or 20:\", mean_train_acc)\n",
    "mean_train_acc = data.loc[(data['temp_update'] == 0.99) & (data['game_size'] > 3), 'train_accuracy'].mean()\n",
    "print(\"Mean accuracy for temperature update 0.99:\", mean_train_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
